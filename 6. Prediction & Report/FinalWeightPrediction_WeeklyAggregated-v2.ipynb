{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xE0ui2bNdFVt"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import Callable, Dict, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import GRUCell, Linear\n",
    "\n",
    "from torch_geometric.nn.inits import zeros\n",
    "from torch_geometric.utils import scatter\n",
    "from torch_geometric.utils._scatter import scatter_argmax\n",
    "\n",
    "TGNMessageStoreType = Dict[int, Tuple[Tensor, Tensor, Tensor, Tensor]]\n",
    "\n",
    "\n",
    "class TGNMemory(torch.nn.Module):\n",
    "    r\"\"\"The Temporal Graph Network (TGN) memory model from the\n",
    "    `\"Temporal Graph Networks for Deep Learning on Dynamic Graphs\"\n",
    "    <https://arxiv.org/abs/2006.10637>`_ paper.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        For an example of using TGN, see `examples/tgn.py\n",
    "        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/\n",
    "        tgn.py>`_.\n",
    "\n",
    "    Args:\n",
    "        num_nodes (int): The number of nodes to save memories for.\n",
    "        raw_msg_dim (int): The raw message dimensionality.\n",
    "        memory_dim (int): The hidden memory dimensionality.\n",
    "        time_dim (int): The time encoding dimensionality.\n",
    "        message_module (torch.nn.Module): The message function which\n",
    "            combines source and destination node memory embeddings, the raw\n",
    "            message and the time encoding.\n",
    "        aggregator_module (torch.nn.Module): The message aggregator function\n",
    "            which aggregates messages to the same destination into a single\n",
    "            representation.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_nodes: int, raw_msg_dim: int, memory_dim: int,\n",
    "                 time_dim: int, message_module: Callable,\n",
    "                 aggregator_module: Callable):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.raw_msg_dim = raw_msg_dim\n",
    "        self.memory_dim = memory_dim\n",
    "        self.time_dim = time_dim\n",
    "\n",
    "        self.msg_s_module = message_module\n",
    "        self.msg_d_module = copy.deepcopy(message_module)\n",
    "        self.aggr_module = aggregator_module\n",
    "        self.time_enc = TimeEncoder(time_dim)\n",
    "        self.gru = GRUCell(message_module.out_channels, memory_dim)\n",
    "\n",
    "        self.register_buffer('memory', torch.empty(num_nodes, memory_dim))\n",
    "        last_update = torch.empty(self.num_nodes, dtype=torch.long)\n",
    "        self.register_buffer('last_update', last_update)\n",
    "        self.register_buffer('_assoc', torch.empty(num_nodes,\n",
    "                                                   dtype=torch.long))\n",
    "\n",
    "        self.msg_s_store = {}\n",
    "        self.msg_d_store = {}\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return self.time_enc.lin.weight.device\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        if hasattr(self.msg_s_module, 'reset_parameters'):\n",
    "            self.msg_s_module.reset_parameters()\n",
    "        if hasattr(self.msg_d_module, 'reset_parameters'):\n",
    "            self.msg_d_module.reset_parameters()\n",
    "        if hasattr(self.aggr_module, 'reset_parameters'):\n",
    "            self.aggr_module.reset_parameters()\n",
    "        self.time_enc.reset_parameters()\n",
    "        self.gru.reset_parameters()\n",
    "        self.reset_state()\n",
    "\n",
    "    def reset_state(self):\n",
    "        \"\"\"Resets the memory to its initial state.\"\"\"\n",
    "        zeros(self.memory)\n",
    "        zeros(self.last_update)\n",
    "        self._reset_message_store()\n",
    "\n",
    "    def detach(self):\n",
    "        \"\"\"Detaches the memory from gradient computation.\"\"\"\n",
    "        self.memory.detach_()\n",
    "\n",
    "    def forward(self, n_id: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"Returns, for all nodes :obj:`n_id`, their current memory and their\n",
    "        last updated timestamp.\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            memory, last_update = self._get_updated_memory(n_id)\n",
    "        else:\n",
    "            memory, last_update = self.memory[n_id], self.last_update[n_id]\n",
    "\n",
    "        return memory, last_update\n",
    "\n",
    "    def update_state(self, src: Tensor, dst: Tensor, t: Tensor,\n",
    "                     raw_msg: Tensor):\n",
    "        \"\"\"Updates the memory with newly encountered interactions\n",
    "        :obj:`(src, dst, t, raw_msg)`.\n",
    "        \"\"\"\n",
    "        n_id = torch.cat([src, dst]).unique()\n",
    "\n",
    "        if self.training:\n",
    "            self._update_memory(n_id)\n",
    "            self._update_msg_store(src, dst, t, raw_msg, self.msg_s_store)\n",
    "            self._update_msg_store(dst, src, t, raw_msg, self.msg_d_store)\n",
    "        else:\n",
    "            self._update_msg_store(src, dst, t, raw_msg, self.msg_s_store)\n",
    "            self._update_msg_store(dst, src, t, raw_msg, self.msg_d_store)\n",
    "            self._update_memory(n_id)\n",
    "\n",
    "    def _reset_message_store(self):\n",
    "        i = self.memory.new_empty((0, ), device=self.device, dtype=torch.long)\n",
    "        msg = self.memory.new_empty((0, self.raw_msg_dim), device=self.device)\n",
    "        # Message store format: (src, dst, t, msg)\n",
    "        self.msg_s_store = {j: (i, i, i, msg) for j in range(self.num_nodes)}\n",
    "        self.msg_d_store = {j: (i, i, i, msg) for j in range(self.num_nodes)}\n",
    "\n",
    "    # def _update_memory(self, n_id: Tensor):\n",
    "    #     memory, last_update = self._get_updated_memory(n_id)\n",
    "    #     self.memory[n_id] = memory\n",
    "    #     self.last_update[n_id] = last_update\n",
    "\n",
    "    def _update_memory(self, n_id):\n",
    "        memory, last_update = self._get_updated_memory(n_id)\n",
    "        # self.memory[n_id] = memory\n",
    "        # self.last_update[n_id] = last_update\n",
    "\n",
    "        self.memory[n_id.long()] = memory\n",
    "        self.last_update[n_id.float().long()] = last_update.long()\n",
    "\n",
    "\n",
    "    def _get_updated_memory(self, n_id: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        self._assoc[n_id] = torch.arange(n_id.size(0), device=n_id.device)\n",
    "\n",
    "        # Compute messages (src -> dst).\n",
    "        msg_s, t_s, src_s, dst_s = self._compute_msg(n_id, self.msg_s_store,\n",
    "                                                     self.msg_s_module)\n",
    "\n",
    "        # Compute messages (dst -> src).\n",
    "        msg_d, t_d, src_d, dst_d = self._compute_msg(n_id, self.msg_d_store,\n",
    "                                                     self.msg_d_module)\n",
    "\n",
    "        # Aggregate messages.\n",
    "        idx = torch.cat([src_s, src_d], dim=0)\n",
    "        msg = torch.cat([msg_s, msg_d], dim=0)\n",
    "        t = torch.cat([t_s, t_d], dim=0)\n",
    "        aggr = self.aggr_module(msg, self._assoc[idx], t, n_id.size(0))\n",
    "\n",
    "        # Get local copy of updated memory.\n",
    "        memory = self.gru(aggr, self.memory[n_id])\n",
    "\n",
    "        # Get local copy of updated `last_update`.\n",
    "        dim_size = self.last_update.size(0)\n",
    "        last_update = scatter(t, idx, 0, dim_size, reduce='max')[n_id]\n",
    "        return memory, last_update\n",
    "\n",
    "\n",
    "    def _update_msg_store(self, src: Tensor, dst: Tensor, t: Tensor,\n",
    "                          raw_msg: Tensor, msg_store: TGNMessageStoreType):\n",
    "        n_id, perm = src.sort()\n",
    "        n_id, count = n_id.unique_consecutive(return_counts=True)\n",
    "        for i, idx in zip(n_id.tolist(), perm.split(count.tolist())):\n",
    "            msg_store[i] = (src[idx], dst[idx], t[idx], raw_msg[idx])\n",
    "\n",
    "    def _compute_msg(self, n_id: Tensor, msg_store: TGNMessageStoreType,\n",
    "                     msg_module: Callable):\n",
    "        data = [msg_store[i] for i in n_id.tolist()]\n",
    "        src, dst, t, raw_msg = list(zip(*data))\n",
    "        src = torch.cat(src, dim=0)\n",
    "        dst = torch.cat(dst, dim=0)\n",
    "        t = torch.cat(t, dim=0)\n",
    "        # Filter out empty tensors to avoid `invalid configuration argument`.\n",
    "        # TODO Investigate why this is needed.\n",
    "        raw_msg = [m for i, m in enumerate(raw_msg) if m.numel() > 0 or i == 0]\n",
    "        raw_msg = torch.cat(raw_msg, dim=0)\n",
    "\n",
    "        #--------------------------adding here----------------------------------#\n",
    "        t = t - self.last_update[src]\n",
    "        t = t.float()\n",
    "        t_enc = self.time_enc(t)\n",
    "        #_______________________________________________________________________#\n",
    "\n",
    "        # t_enc = self.time_enc(t - self.last_update[src])\n",
    "\n",
    "        msg = msg_module(self.memory[src], self.memory[dst], raw_msg, t_enc)\n",
    "\n",
    "        return msg, t, src, dst\n",
    "\n",
    "    def train(self, mode: bool = True):\n",
    "        \"\"\"Sets the module in training mode.\"\"\"\n",
    "        if self.training and not mode:\n",
    "            # Flush message store to memory in case we just entered eval mode.\n",
    "            self._update_memory(\n",
    "                torch.arange(self.num_nodes, device=self.memory.device))\n",
    "            self._reset_message_store()\n",
    "        super().train(mode)\n",
    "\n",
    "\n",
    "class IdentityMessage(torch.nn.Module):\n",
    "    def __init__(self, raw_msg_dim: int, memory_dim: int, time_dim: int):\n",
    "        super().__init__()\n",
    "        self.out_channels = raw_msg_dim + 2 * memory_dim + time_dim\n",
    "\n",
    "    def forward(self, z_src: Tensor, z_dst: Tensor, raw_msg: Tensor,\n",
    "                t_enc: Tensor):\n",
    "        return torch.cat([z_src, z_dst, raw_msg, t_enc], dim=-1)\n",
    "\n",
    "\n",
    "class LastAggregator(torch.nn.Module):\n",
    "    def forward(self, msg: Tensor, index: Tensor, t: Tensor, dim_size: int):\n",
    "        argmax = scatter_argmax(t, index, dim=0, dim_size=dim_size)\n",
    "        out = msg.new_zeros((dim_size, msg.size(-1)))\n",
    "        mask = argmax < msg.size(0)  # Filter items with at least one entry.\n",
    "        out[mask] = msg[argmax[mask]]\n",
    "        return out\n",
    "\n",
    "\n",
    "class MeanAggregator(torch.nn.Module):\n",
    "    def forward(self, msg: Tensor, index: Tensor, t: Tensor, dim_size: int):\n",
    "        return scatter(msg, index, dim=0, dim_size=dim_size, reduce='mean')\n",
    "\n",
    "\n",
    "class TimeEncoder(torch.nn.Module):\n",
    "    def __init__(self, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.lin = Linear(1, out_channels)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "\n",
    "    def forward(self, t: Tensor) -> Tensor:\n",
    "        return self.lin(t.view(-1, 1)).cos()\n",
    "\n",
    "\n",
    "class LastNeighborLoader:\n",
    "    def __init__(self, num_nodes: int, size: int, device=None):\n",
    "        self.size = size\n",
    "\n",
    "        self.neighbors = torch.empty((num_nodes, size), dtype=torch.long,\n",
    "                                     device=device)\n",
    "        self.e_id = torch.empty((num_nodes, size), dtype=torch.long,\n",
    "                                device=device)\n",
    "        self._assoc = torch.empty(num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "        self.reset_state()\n",
    "\n",
    "    def __call__(self, n_id: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "        neighbors = self.neighbors[n_id]\n",
    "        nodes = n_id.view(-1, 1).repeat(1, self.size)\n",
    "        e_id = self.e_id[n_id]\n",
    "\n",
    "        # Filter invalid neighbors (identified by `e_id < 0`).\n",
    "        mask = e_id >= 0\n",
    "        neighbors, nodes, e_id = neighbors[mask], nodes[mask], e_id[mask]\n",
    "\n",
    "        # Relabel node indices.\n",
    "        n_id = torch.cat([n_id, neighbors]).unique()\n",
    "        self._assoc[n_id] = torch.arange(n_id.size(0), device=n_id.device)\n",
    "        neighbors, nodes = self._assoc[neighbors], self._assoc[nodes]\n",
    "\n",
    "        return n_id, torch.stack([neighbors, nodes]), e_id\n",
    "\n",
    "    def insert(self, src: Tensor, dst: Tensor):\n",
    "        # Inserts newly encountered interactions into an ever-growing\n",
    "        # (undirected) temporal graph.\n",
    "\n",
    "        # Collect central nodes, their neighbors and the current event ids.\n",
    "        neighbors = torch.cat([src, dst], dim=0)\n",
    "        nodes = torch.cat([dst, src], dim=0)\n",
    "        e_id = torch.arange(self.cur_e_id, self.cur_e_id + src.size(0),\n",
    "                            device=src.device).repeat(2)\n",
    "        self.cur_e_id += src.numel()\n",
    "\n",
    "        # Convert newly encountered interaction ids so that they point to\n",
    "        # locations of a \"dense\" format of shape [num_nodes, size].\n",
    "        nodes, perm = nodes.sort()\n",
    "        neighbors, e_id = neighbors[perm], e_id[perm]\n",
    "\n",
    "        n_id = nodes.unique()\n",
    "        self._assoc[n_id] = torch.arange(n_id.numel(), device=n_id.device)\n",
    "\n",
    "        dense_id = torch.arange(nodes.size(0), device=nodes.device) % self.size\n",
    "        dense_id += self._assoc[nodes].mul_(self.size)\n",
    "\n",
    "        dense_e_id = e_id.new_full((n_id.numel() * self.size, ), -1)\n",
    "        dense_e_id[dense_id] = e_id\n",
    "        dense_e_id = dense_e_id.view(-1, self.size)\n",
    "\n",
    "        dense_neighbors = e_id.new_empty(n_id.numel() * self.size)\n",
    "        dense_neighbors[dense_id] = neighbors\n",
    "        dense_neighbors = dense_neighbors.view(-1, self.size)\n",
    "\n",
    "        # Collect new and old interactions...\n",
    "        e_id = torch.cat([self.e_id[n_id, :self.size], dense_e_id], dim=-1)\n",
    "        neighbors = torch.cat(\n",
    "            [self.neighbors[n_id, :self.size], dense_neighbors], dim=-1)\n",
    "\n",
    "        # And sort them based on `e_id`.\n",
    "        e_id, perm = e_id.topk(self.size, dim=-1)\n",
    "        self.e_id[n_id] = e_id\n",
    "        self.neighbors[n_id] = torch.gather(neighbors, 1, perm)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.cur_e_id = 0\n",
    "        self.e_id.fill_(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8ydxHUKZ_LRo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from torch_geometric.datasets import JODIEDataset\n",
    "from torch_geometric.loader import TemporalDataLoader\n",
    "# from torch_geometric.nn import TGNMemory, TransformerConv\n",
    "from torch_geometric.nn import TransformerConv\n",
    "from torch_geometric.nn.models.tgn import (\n",
    "    IdentityMessage,\n",
    "    LastAggregator,\n",
    "    LastNeighborLoader,\n",
    ")\n",
    "\n",
    "import os\n",
    "from torch.nn import BCEWithLogitsLoss, MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TmMhbmMVAhH_"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "pTFSM42XAyGc",
    "outputId": "1e3b5c6f-3b00-4cb0-9ec9-e84a9771231d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_zone_encoded</th>\n",
       "      <th>end_zone_encoded</th>\n",
       "      <th>weight</th>\n",
       "      <th>time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134446</th>\n",
       "      <td>263</td>\n",
       "      <td>247</td>\n",
       "      <td>1</td>\n",
       "      <td>551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134447</th>\n",
       "      <td>263</td>\n",
       "      <td>249</td>\n",
       "      <td>6</td>\n",
       "      <td>551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134448</th>\n",
       "      <td>263</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134449</th>\n",
       "      <td>263</td>\n",
       "      <td>260</td>\n",
       "      <td>2</td>\n",
       "      <td>551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134450</th>\n",
       "      <td>263</td>\n",
       "      <td>262</td>\n",
       "      <td>212</td>\n",
       "      <td>551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3134451 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         start_zone_encoded  end_zone_encoded  weight  time  target\n",
       "0                         4                12       2     0       0\n",
       "1                         4                13      15     0       0\n",
       "2                         4                17       1     0       0\n",
       "3                         4                25       3     0       0\n",
       "4                         4                33      13     0       0\n",
       "...                     ...               ...     ...   ...     ...\n",
       "3134446                 263               247       1   551       0\n",
       "3134447                 263               249       6   551       0\n",
       "3134448                 263               256       3   551       0\n",
       "3134449                 263               260       2   551       0\n",
       "3134450                 263               262     212   551       0\n",
       "\n",
       "[3134451 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('weeklyAggregatedCitibike_for_train.csv')\n",
    "raw_data[\"target\"] = 0\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3ejwbCDbChLs"
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch_geometric.data import TemporalData\n",
    "\n",
    "data_temporal = TemporalData(\n",
    "    src=Tensor(raw_data[\"start_zone_encoded\"]).long(),\n",
    "    dst=Tensor(raw_data[\"end_zone_encoded\"]).long(),\n",
    "    t=Tensor(raw_data[\"time\"]),\n",
    "    msg=Tensor(raw_data[\"weight\"]).unsqueeze(-1)\n",
    ")\n",
    "\n",
    "data_temporal.y = Tensor(raw_data[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tqn-SM4oEPhB",
    "outputId": "335cb874-f17d-40f9-e780-b3782490e67a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemporalData(src=[3134451], dst=[3134451], t=[3134451], msg=[3134451, 1], y=[3134451])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCzDrBx7ERuX",
    "outputId": "2d94a1c1-be02-462c-d5b8-1cd988e7b7fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source nodes: tensor([  4,   4,   4,  ..., 263, 263, 263])\n",
      "Destination nodes: tensor([ 12,  13,  17,  ..., 256, 260, 262])\n",
      "Timestamps: tensor([  0.,   0.,   0.,  ..., 551., 551., 551.])\n",
      "Messages or edge features: tensor([[  2.],\n",
      "        [ 15.],\n",
      "        [  1.],\n",
      "        ...,\n",
      "        [  3.],\n",
      "        [  2.],\n",
      "        [212.]])\n",
      "Target values: tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Source nodes:\", data_temporal.src)\n",
    "print(\"Destination nodes:\", data_temporal.dst)\n",
    "print(\"Timestamps:\", data_temporal.t)\n",
    "print(\"Messages or edge features:\", data_temporal.msg)\n",
    "print(\"Target values:\", data_temporal.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yg8ZOLQtEdAn",
    "outputId": "30e78fb7-8797-4f99-c2b9-816a0d69e1de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source nodes: 3134451\n",
      "Destination nodes: 3134451\n",
      "Timestamps: 3134451\n",
      "Messages or edge features: 3134451\n",
      "Target values: 3134451\n"
     ]
    }
   ],
   "source": [
    "print(\"Source nodes:\", len(data_temporal.src))\n",
    "print(\"Destination nodes:\", len(data_temporal.dst))\n",
    "print(\"Timestamps:\", len(data_temporal.t))\n",
    "print(\"Messages or edge features:\", len(data_temporal.msg))\n",
    "print(\"Target values:\", len(data_temporal.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9uQrGwPfEmNy",
    "outputId": "b00bc08a-382a-4dde-bcec-e2f6b053eb2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source nodes: tensor([  2,   4,   7,   8,  12,  13,  14,  17,  18,  20,  21,  22,  24,  25,\n",
      "         26,  28,  31,  32,  33,  34,  35,  36,  37,  39,  40,  41,  42,  43,\n",
      "         45,  47,  48,  49,  50,  52,  54,  55,  57,  59,  60,  61,  62,  63,\n",
      "         65,  66,  67,  68,  69,  70,  71,  72,  74,  75,  76,  77,  78,  79,\n",
      "         80,  81,  82,  83,  85,  87,  88,  89,  90,  91,  92,  93,  94,  96,\n",
      "         97, 100, 102, 105, 106, 107, 111, 112, 113, 114, 116, 117, 119, 120,\n",
      "        123, 125, 126, 127, 128, 129, 133, 134, 136, 137, 138, 140, 141, 142,\n",
      "        143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 157, 158, 159, 160,\n",
      "        161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 173, 174, 177, 179,\n",
      "        181, 182, 185, 186, 188, 189, 190, 193, 194, 195, 196, 198, 202, 206,\n",
      "        207, 209, 211, 212, 213, 217, 220, 222, 223, 224, 225, 226, 227, 228,\n",
      "        229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
      "        243, 244, 246, 247, 248, 249, 254, 255, 256, 257, 260, 261, 262, 263])\n",
      "Destination nodes: tensor([  4,   7,   8,  12,  13,  14,  17,  18,  20,  24,  25,  26,  31,  33,\n",
      "         34,  35,  36,  37,  40,  41,  42,  43,  45,  47,  48,  49,  50,  52,\n",
      "         54,  57,  59,  60,  61,  62,  65,  66,  68,  69,  70,  71,  72,  74,\n",
      "         75,  78,  79,  80,  82,  83,  85,  87,  88,  89,  90,  93,  94,  97,\n",
      "        100, 102, 105, 106, 107, 111, 112, 113, 114, 116, 119, 120, 125, 126,\n",
      "        127, 128, 129, 133, 136, 137, 140, 141, 142, 143, 144, 145, 146, 147,\n",
      "        148, 151, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167,\n",
      "        168, 169, 170, 173, 174, 177, 179, 181, 186, 188, 189, 190, 193, 194,\n",
      "        195, 198, 202, 209, 211, 217, 220, 223, 224, 225, 226, 227, 228, 229,\n",
      "        230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244,\n",
      "        246, 247, 249, 255, 256, 257, 260, 261, 262, 263])\n",
      "Timestamps: tensor([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
      "         12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,\n",
      "         24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,  34.,  35.,\n",
      "         36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.,\n",
      "         48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,  56.,  57.,  58.,  59.,\n",
      "         60.,  61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,\n",
      "         72.,  73.,  74.,  75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,\n",
      "         84.,  85.,  86.,  87.,  88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,\n",
      "         96.,  97.,  98.,  99., 100., 101., 102., 103., 104., 105., 106., 107.,\n",
      "        108., 109., 110., 111., 112., 113., 114., 115., 116., 117., 118., 119.,\n",
      "        120., 121., 122., 123., 124., 125., 126., 127., 128., 129., 130., 131.,\n",
      "        132., 133., 134., 135., 136., 137., 138., 139., 140., 141., 142., 143.,\n",
      "        144., 145., 146., 147., 148., 149., 150., 151., 152., 153., 154., 155.,\n",
      "        156., 157., 158., 159., 160., 161., 162., 163., 164., 165., 166., 167.,\n",
      "        168., 169., 170., 171., 172., 173., 174., 175., 176., 177., 178., 179.,\n",
      "        180., 181., 182., 183., 184., 185., 186., 187., 188., 189., 190., 191.,\n",
      "        192., 193., 194., 195., 196., 197., 198., 199., 200., 201., 202., 203.,\n",
      "        204., 205., 206., 207., 208., 209., 210., 211., 212., 213., 214., 215.,\n",
      "        216., 217., 218., 219., 220., 221., 222., 223., 224., 225., 226., 227.,\n",
      "        228., 229., 230., 231., 232., 233., 234., 235., 236., 237., 238., 239.,\n",
      "        240., 241., 242., 243., 244., 245., 246., 247., 248., 249., 250., 251.,\n",
      "        252., 253., 254., 255., 256., 257., 258., 259., 260., 261., 262., 263.,\n",
      "        264., 265., 266., 267., 268., 269., 270., 271., 272., 273., 274., 275.,\n",
      "        276., 277., 278., 279., 280., 281., 282., 283., 284., 285., 286., 287.,\n",
      "        288., 289., 290., 291., 292., 293., 294., 295., 296., 297., 298., 299.,\n",
      "        300., 301., 302., 303., 304., 305., 306., 307., 308., 309., 310., 311.,\n",
      "        312., 313., 314., 315., 316., 317., 318., 319., 320., 321., 322., 323.,\n",
      "        324., 325., 326., 327., 328., 329., 330., 331., 332., 333., 334., 335.,\n",
      "        336., 337., 338., 339., 340., 341., 342., 343., 344., 345., 346., 347.,\n",
      "        348., 349., 350., 351., 352., 353., 354., 355., 356., 357., 358., 359.,\n",
      "        360., 361., 362., 363., 364., 365., 366., 367., 368., 369., 370., 371.,\n",
      "        372., 373., 374., 375., 376., 377., 378., 379., 380., 381., 382., 383.,\n",
      "        384., 385., 386., 387., 388., 389., 390., 391., 392., 393., 394., 395.,\n",
      "        396., 397., 398., 399., 400., 401., 402., 403., 404., 405., 406., 407.,\n",
      "        408., 409., 410., 411., 412., 413., 414., 415., 416., 417., 418., 419.,\n",
      "        420., 421., 422., 423., 424., 425., 426., 427., 428., 429., 430., 431.,\n",
      "        432., 433., 434., 435., 436., 437., 438., 439., 440., 441., 442., 443.,\n",
      "        444., 445., 446., 447., 448., 449., 450., 451., 452., 453., 454., 455.,\n",
      "        456., 457., 458., 459., 460., 461., 462., 463., 464., 465., 466., 467.,\n",
      "        468., 469., 470., 471., 472., 473., 474., 475., 476., 477., 478., 479.,\n",
      "        480., 481., 482., 483., 484., 485., 486., 487., 488., 489., 490., 491.,\n",
      "        492., 493., 494., 495., 496., 497., 498., 499., 500., 501., 502., 503.,\n",
      "        504., 505., 506., 507., 508., 509., 510., 511., 512., 513., 514., 515.,\n",
      "        516., 517., 518., 519., 520., 521., 522., 523., 524., 525., 526., 527.,\n",
      "        528., 529., 530., 531., 532., 533., 534., 535., 536., 537., 538., 539.,\n",
      "        540., 541., 542., 543., 544., 545., 546., 547., 548., 549., 550., 551.])\n",
      "Messages or edge features: tensor([1.0000e+00, 2.0000e+00, 3.0000e+00,  ..., 3.9180e+03, 4.0170e+03,\n",
      "        4.0250e+03])\n",
      "Target values: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Source nodes:\", data_temporal.src.unique())\n",
    "print(\"Destination nodes:\", data_temporal.dst.unique())\n",
    "print(\"Timestamps:\", data_temporal.t.unique())\n",
    "print(\"Messages or edge features:\", data_temporal.msg.unique())\n",
    "print(\"Target values:\", data_temporal.y.unique())\n",
    "\n",
    "# source_unique = [x for x in data_temporal.src.unique() if x not in data_temporal.dst.unique()]\n",
    "# destination_unique = [x for x in data_temporal.dst.unique() if x not in data_temporal.src.unique()]\n",
    "\n",
    "# print(\"Source not in destination:\",source_unique)\n",
    "# print(\"Destination not in source:\",destination_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dua_CCCnIOL8",
    "outputId": "b76609fd-9ad6-4411-853e-8e422fa6b7a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "print(data_temporal.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TmMA5FwnjMLv"
   },
   "outputs": [],
   "source": [
    "data_temporal = data_temporal.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQNr3g5IpC9t",
    "outputId": "1275d5cf-c730-446a-c523-aabde4bf0185"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemporalData(src=[3134451], dst=[3134451], t=[3134451], msg=[3134451, 1], y=[3134451])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "clO1CyCvkut5"
   },
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = data_temporal.train_val_test_split(val_ratio=0.15, test_ratio=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AZRryPVBk2Zr"
   },
   "outputs": [],
   "source": [
    "train_loader = TemporalDataLoader(\n",
    "    train_data,\n",
    "    batch_size=200,\n",
    "    neg_sampling_ratio=1.0,\n",
    ")\n",
    "val_loader = TemporalDataLoader(\n",
    "    val_data,\n",
    "    batch_size=200,\n",
    "    neg_sampling_ratio=1.0,\n",
    ")\n",
    "test_loader = TemporalDataLoader(\n",
    "    test_data,\n",
    "    batch_size=200,\n",
    "    neg_sampling_ratio=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7tb0hK_8vvW",
    "outputId": "ea77d6d2-0047-4252-a6b5-f089f69c3904"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  4,   4,   4,  ..., 263, 263, 263])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZvcCSKfGqK2w"
   },
   "outputs": [],
   "source": [
    "neighbor_loader = LastNeighborLoader(data_temporal.num_nodes, size=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Ae71i4zdqftz"
   },
   "outputs": [],
   "source": [
    "class GraphAttentionEmbedding(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, msg_dim, time_enc):\n",
    "        super().__init__()\n",
    "        self.time_enc = time_enc\n",
    "        edge_dim = msg_dim + time_enc.out_channels\n",
    "        self.conv = TransformerConv(in_channels, out_channels // 2, heads=2,\n",
    "                                    dropout=0.1, edge_dim=edge_dim)\n",
    "\n",
    "    def forward(self, x, last_update, edge_index, t, msg):\n",
    "        rel_t = last_update[edge_index[0]] - t\n",
    "        rel_t_enc = self.time_enc(rel_t.to(x.dtype))\n",
    "        edge_attr = torch.cat([rel_t_enc, msg], dim=-1)\n",
    "        return self.conv(x, edge_index, edge_attr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Y5924qZGRBA3"
   },
   "outputs": [],
   "source": [
    "class EdgeWeightPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.lin_src = Linear(in_channels, in_channels)\n",
    "        self.lin_dst = Linear(in_channels, in_channels)\n",
    "        self.lin_final = Linear(in_channels, 1)  # Outputs a single value for edge weight\n",
    "\n",
    "    def forward(self, z_src, z_dst):\n",
    "        h = self.lin_src(z_src) + self.lin_dst(z_dst)\n",
    "        h = h.relu()\n",
    "        return self.lin_final(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6QZIpu1xqywA"
   },
   "outputs": [],
   "source": [
    "memory_dim = time_dim = embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L0hV2CT_3g5r",
    "outputId": "a58cc107-0ce4-4bb5-d878-5f15da7a7313"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temporal.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "BxuvjTBTq2br"
   },
   "outputs": [],
   "source": [
    "memory = TGNMemory(\n",
    "    data_temporal.num_nodes,\n",
    "    data_temporal.msg.size(-1),\n",
    "    memory_dim,\n",
    "    time_dim,\n",
    "    message_module=IdentityMessage(data_temporal.msg.size(-1), memory_dim, time_dim),\n",
    "    aggregator_module=LastAggregator(),\n",
    ").to(device)\n",
    "\n",
    "gnn = GraphAttentionEmbedding(\n",
    "    in_channels=memory_dim,\n",
    "    out_channels=embedding_dim,\n",
    "    msg_dim=data_temporal.msg.size(-1),\n",
    "    time_enc=memory.time_enc,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "vbpNvvdUrBMG"
   },
   "outputs": [],
   "source": [
    "# link_pred = LinkPredictor(in_channels=embedding_dim).to(device)\n",
    "edge_weight_pred = EdgeWeightPredictor(in_channels=embedding_dim).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    set(memory.parameters()) | set(gnn.parameters())\n",
    "    | set(edge_weight_pred.parameters()), lr=0.0001)\n",
    "\n",
    "# Assuming the existence of the link is still a binary classification problem\n",
    "bce_loss = BCEWithLogitsLoss()\n",
    "mse_loss = MSELoss()  # Assuming weights are a regression problem\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "weight_criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Helper vector to map global node indices to local ones.\n",
    "assoc = torch.empty(data_temporal.num_nodes, dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "A6oCVYUZri3D"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    memory.train()\n",
    "    gnn.train()\n",
    "    # link_pred.train()\n",
    "    edge_weight_pred.train()\n",
    "\n",
    "    memory.reset_state()  # Start with a fresh memory.\n",
    "    neighbor_loader.reset_state()  # Start with an empty graph.\n",
    "\n",
    "    total_loss = 0\n",
    "    # total_weight_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        n_id, edge_index, e_id = neighbor_loader(batch.n_id.long())\n",
    "        assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "        # n_id = n_id.long()\n",
    "\n",
    "        # Get updated memory of all nodes involved in the computation.\n",
    "        z, last_update = memory(n_id)\n",
    "        z = gnn(z, last_update, edge_index, data_temporal.t[e_id].to(device),\n",
    "                data_temporal.msg[e_id].to(device))\n",
    "\n",
    "        # pos_out = link_pred(z[assoc[batch.src]], z[assoc[batch.dst]])\n",
    "        # neg_out = link_pred(z[assoc[batch.src]], z[assoc[batch.neg_dst]])\n",
    "\n",
    "        weight_pred = edge_weight_pred(z[assoc[batch.src]], z[assoc[batch.dst]])\n",
    "        weight_loss = weight_criterion(weight_pred, batch.msg.view(-1, 1))\n",
    "\n",
    "        # loss = criterion(pos_out, torch.ones_like(pos_out))\n",
    "        # loss += criterion(neg_out, torch.zeros_like(neg_out))\n",
    "        # loss += weight_loss  # Include edge weight loss in the total loss\n",
    "\n",
    "        memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
    "        neighbor_loader.insert(batch.src, batch.dst)\n",
    "\n",
    "        weight_loss.backward()\n",
    "        optimizer.step()\n",
    "        memory.detach()\n",
    "        total_loss += float(weight_loss) * batch.num_events\n",
    "\n",
    "    return total_loss / train_data.num_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "p40dGltzuo8x"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    memory.eval()\n",
    "    gnn.eval()\n",
    "    # link_pred.eval()\n",
    "    edge_weight_pred.eval()\n",
    "\n",
    "    torch.manual_seed(12345)  # Ensure deterministic sampling across epochs.\n",
    "\n",
    "    # aps = []\n",
    "    # weight_aps, weight_aucs = [], []  # To store APS and AUC for weights\n",
    "    all_predictions = []    # To store prediction results and node info\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        n_id, edge_index, e_id = neighbor_loader(batch.n_id.long())\n",
    "        assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "        # n_id = n_id.long()\n",
    "\n",
    "        z, last_update = memory(n_id)\n",
    "        z = gnn(z, last_update, edge_index, data_temporal.t[e_id].to(device),\n",
    "                data_temporal.msg[e_id].to(device))\n",
    "        # outputs = link_pred(z[assoc[batch.src.long()]], z[assoc[batch.dst.long()]])\n",
    "        # pos_out, pos_weights = outputs[:, 0], outputs[:, 1]\n",
    "        # neg_out, neg_weights = link_pred(z[assoc[batch.src.long()]], z[assoc[batch.neg_dst.long()]]).split(1, dim=1)\n",
    "\n",
    "        # y_pred = torch.cat([pos_out.sigmoid().unsqueeze(1), pos_weights.unsqueeze(1)], dim=1).cpu()\n",
    "\n",
    "        # pos_out = link_pred(z[assoc[batch.src]], z[assoc[batch.dst]])\n",
    "        # neg_out = link_pred(z[assoc[batch.src]], z[assoc[batch.neg_dst]])\n",
    "\n",
    "        weight_pred = edge_weight_pred(z[assoc[batch.src]], z[assoc[batch.dst]])\n",
    "\n",
    "        # if torch.cuda.is_available():\n",
    "        #   y_true = torch.cat(\n",
    "        #     [torch.ones(pos_out.size(0), 1).to(device),\n",
    "        #      batch.msg.to(device)], dim=0).cpu()\n",
    "            # batch.msg.to(device).unsqueeze(1)], dim=0).cpu()\n",
    "        # else:\n",
    "        #   y_true = torch.cat(\n",
    "        #     [torch.ones(pos_out.size(0), 1),\n",
    "        #      batch.msg], dim=0).cpu()\n",
    "            # batch.msg.unsqueeze(1)], dim=0).cpu()\n",
    "\n",
    "        # if torch.cuda.is_available():\n",
    "        #   y_true = torch.cat(\n",
    "        #       [torch.ones(pos_out.size(0), 1).to(device),\n",
    "        #        batch.msg.to(device)], dim=0).cpu()\n",
    "        # else:\n",
    "        #   y_true = torch.cat(\n",
    "        #     [torch.ones(pos_out.size(0), 1),\n",
    "        #      batch.msg], dim=0).cpu()  # Assumes batch.msg is properly scaled\n",
    "\n",
    "        # y_true = torch.cat(\n",
    "        #     [torch.ones(pos_out.size(0), 1),\n",
    "        #      batch.msg.unsqueeze(1)], dim=0).cpu()  # Assumes batch.msg is properly scaled\n",
    "\n",
    "        # src_nodes = batch.src.cpu().numpy()\n",
    "        # dst_nodes = batch.dst.cpu().numpy()\n",
    "        src_nodes = batch.src.cpu().numpy()\n",
    "        dst_nodes = batch.dst.cpu().numpy()\n",
    "        all_predictions.append((weight_pred, src_nodes, dst_nodes))\n",
    "\n",
    "        # Calculate APS and AUC for link existence\n",
    "        # aps.append(average_precision_score(y_true[:, 0], weight_pred[:, 0]))\n",
    "        # aucs.append(roc_auc_score(y_true[:, 0], weight_pred[:, 0]))\n",
    "\n",
    "        # Calculate APS and AUC for weights\n",
    "        # weight_aps.append(average_precision_score(y_true[:, 1], y_pred[:, 1]))  # Added for weight APS\n",
    "        # weight_aucs.append(roc_auc_score(y_true[:, 1], y_pred[:, 1]))  # Added for weight AUC\n",
    "\n",
    "        memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
    "        neighbor_loader.insert(batch.src, batch.dst)\n",
    "\n",
    "    return all_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T2drgmlhyE1v",
    "outputId": "caee7778-eabd-40f1-ceb4-eab49a717ff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 10169.4605\n",
      "Epoch: 02, Loss: 8861.9021\n",
      "Epoch: 03, Loss: 8358.6989\n",
      "Epoch: 04, Loss: 8165.7161\n",
      "Epoch: 05, Loss: 7934.1791\n",
      "Epoch: 06, Loss: 8326.5592\n",
      "Epoch: 07, Loss: 8052.3375\n",
      "Epoch: 08, Loss: 7508.4522\n",
      "Epoch: 09, Loss: 7368.9030\n",
      "Epoch: 10, Loss: 7407.0726\n",
      "Epoch: 11, Loss: 7014.4421\n",
      "Epoch: 12, Loss: 7123.7813\n",
      "Epoch: 13, Loss: 6582.5375\n",
      "Epoch: 14, Loss: 6514.0757\n",
      "Epoch: 15, Loss: 7060.3285\n",
      "Epoch: 16, Loss: 7934.2216\n",
      "Epoch: 17, Loss: 6658.9212\n",
      "Epoch: 18, Loss: 7664.7158\n",
      "Epoch: 19, Loss: 6683.9084\n",
      "Epoch: 20, Loss: 7187.7544\n",
      "Epoch: 21, Loss: 5789.3716\n",
      "Epoch: 22, Loss: 6010.8711\n",
      "Epoch: 23, Loss: 5724.8119\n",
      "Epoch: 24, Loss: 7477.5374\n",
      "Epoch: 25, Loss: 5685.0806\n",
      "Epoch: 26, Loss: 6033.4723\n",
      "Epoch: 27, Loss: 6832.1084\n",
      "Epoch: 28, Loss: 5632.5736\n",
      "Epoch: 29, Loss: 5529.2994\n",
      "Epoch: 30, Loss: 5194.0642\n",
      "Epoch: 31, Loss: 5179.9064\n",
      "Epoch: 32, Loss: 4850.7872\n",
      "Epoch: 33, Loss: 6428.4975\n",
      "Epoch: 34, Loss: 6698.3564\n",
      "Epoch: 35, Loss: 6380.6649\n",
      "Epoch: 36, Loss: 5714.1553\n",
      "Epoch: 37, Loss: 5505.9633\n",
      "Epoch: 38, Loss: 5015.3489\n",
      "Epoch: 39, Loss: 4882.5766\n",
      "Epoch: 40, Loss: 5760.3058\n",
      "Epoch: 41, Loss: 6774.0819\n",
      "Epoch: 42, Loss: 5405.8357\n",
      "Epoch: 43, Loss: 5413.2227\n",
      "Epoch: 44, Loss: 5470.8306\n",
      "Epoch: 45, Loss: 6267.4700\n",
      "Epoch: 46, Loss: 6429.6868\n",
      "Epoch: 47, Loss: 6646.6909\n",
      "Epoch: 48, Loss: 8405.0048\n",
      "Epoch: 49, Loss: 6766.5074\n",
      "Epoch: 50, Loss: 7728.6357\n",
      "Epoch: 51, Loss: 7422.1175\n",
      "Epoch: 52, Loss: 6951.0975\n",
      "Epoch: 53, Loss: 6144.6404\n",
      "Epoch: 54, Loss: 6290.9024\n",
      "Epoch: 55, Loss: 7993.9721\n",
      "Epoch: 56, Loss: 6917.4974\n",
      "Epoch: 57, Loss: 6422.2220\n",
      "Epoch: 58, Loss: 5728.3195\n",
      "Epoch: 59, Loss: 6429.0777\n",
      "Epoch: 60, Loss: 5424.5902\n",
      "Epoch: 61, Loss: 5637.8050\n",
      "Epoch: 62, Loss: 5488.8558\n",
      "Epoch: 63, Loss: 5313.2840\n",
      "Epoch: 64, Loss: 5341.3138\n",
      "Epoch: 65, Loss: 5746.2684\n",
      "Epoch: 66, Loss: 5632.6734\n",
      "Epoch: 67, Loss: 5381.7616\n",
      "Epoch: 68, Loss: 5326.4552\n",
      "Epoch: 69, Loss: 10578.1266\n",
      "Epoch: 70, Loss: 6121.7771\n",
      "Epoch: 71, Loss: 5948.3953\n",
      "Epoch: 72, Loss: 5585.1158\n",
      "Epoch: 73, Loss: 5421.3370\n",
      "Epoch: 74, Loss: 5156.6957\n",
      "Epoch: 75, Loss: 6697.9435\n",
      "Epoch: 76, Loss: 7275.0927\n",
      "Epoch: 77, Loss: 7358.9397\n",
      "Epoch: 78, Loss: 6400.7409\n",
      "Epoch: 79, Loss: 8289.8973\n",
      "Epoch: 80, Loss: 7297.1570\n",
      "Epoch: 81, Loss: 6846.2135\n",
      "Epoch: 82, Loss: 7088.8141\n",
      "Epoch: 83, Loss: 7639.8510\n",
      "Epoch: 84, Loss: 6044.7274\n",
      "Epoch: 85, Loss: 7419.8891\n",
      "Epoch: 86, Loss: 7038.5662\n",
      "Epoch: 87, Loss: 7287.1049\n",
      "Epoch: 88, Loss: 5827.2280\n",
      "Epoch: 89, Loss: 5804.9989\n",
      "Epoch: 90, Loss: 5281.4802\n",
      "Epoch: 91, Loss: 6420.5896\n",
      "Epoch: 92, Loss: 5201.8140\n",
      "Epoch: 93, Loss: 6357.7823\n",
      "Epoch: 94, Loss: 8129.2768\n",
      "Epoch: 95, Loss: 6411.2493\n",
      "Epoch: 96, Loss: 6289.7261\n",
      "Epoch: 97, Loss: 6558.8845\n",
      "Epoch: 98, Loss: 6399.6522\n",
      "Epoch: 99, Loss: 7390.1432\n",
      "Epoch: 100, Loss: 6567.4326\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "    val_preds = test(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tcAoitPHKwsH"
   },
   "outputs": [],
   "source": [
    "test_preds = test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Cyz9ekRzQdo",
    "outputId": "6ec4d48a-c2ef-448a-fb27-1601d54efd1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2329"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CHs4QTx5iNNL",
    "outputId": "1343d2f3-3e26-4907-9593-e0685a84aa28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeWeightPredictor(\n",
       "  (lin_src): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (lin_dst): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (lin_final): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "\n",
    "# # Assume memory, gnn, and edge_weight_pred are your trained model instances\n",
    "# torch.save(memory.state_dict(), 'memory.pth')\n",
    "# torch.save(gnn.state_dict(), 'gnn.pth')\n",
    "# torch.save(edge_weight_pred.state_dict(), 'edge_weight_pred.pth')\n",
    "\n",
    "# # Assuming the model classes are available as MemoryModel, GNNModel, EdgeWeightModel\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# memory.load_state_dict(torch.load('memory.pth', map_location=device))\n",
    "# memory.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# gnn.load_state_dict(torch.load('gnn.pth', map_location=device))\n",
    "# gnn.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# edge_weight_pred.load_state_dict(torch.load('edge_weight_pred.pth', map_location=device))\n",
    "# edge_weight_pred.eval()  # Set the model to evaluation mode\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
