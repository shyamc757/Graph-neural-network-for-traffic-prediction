{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf56d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"EDA/Yellow_Taxi/sliding_years\"\n",
    "\n",
    "if not(os.path.exists(base_dir)):\n",
    "    os.makedirs(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff38ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_graph_creation(df, window_len, overlap_len):\n",
    "    \n",
    "    df = df[~((df['PULocationID'] == 264) | (df['PULocationID'] == 265) | (df['DOLocationID'] == 264) | (df['DOLocationID'] == 265))]\n",
    "    df = df.sort_values(by = 'start_time').reset_index()\n",
    "    df['start_time'] = pd.to_datetime(df['start_time'], unit = 's')\n",
    "    df['stop_time'] = pd.to_datetime(df['stop_time'], unit = 's')\n",
    "    df = df[['PULocationID', 'DOLocationID', 'start_time', 'stop_time', 'passenger_count', 'weight']]\n",
    "\n",
    "    window_size = pd.DateOffset(months=window_len)\n",
    "    overlap_size = pd.DateOffset(months=overlap_len)\n",
    "\n",
    "    # Adjust start time to the beginning of the day\n",
    "    start_time = df['start_time'].min().replace(day=1, hour=0, minute=0, second=0)\n",
    "    # print(f'start time : {start_time}')\n",
    "\n",
    "    # Adjust stop time to the end of the day\n",
    "    stop_time = (df['stop_time'].max() + pd.DateOffset(months=1)).normalize()\n",
    "    # print(f'stop time : {stop_time}')\n",
    "\n",
    "    window_graphs_total = []\n",
    "    days = []\n",
    "    \n",
    "    end_time = start_time + window_size\n",
    "    # print(f'end time : {end_time}')\n",
    "    # Iterate over sliding windows with overlap\n",
    "    while end_time <= stop_time:\n",
    "        # Filter the DataFrame for data within the current window\n",
    "        window_data = df[(df['start_time'] >= start_time) & (df['stop_time'] < end_time)]\n",
    "\n",
    "        # Group by pick-up and drop-off locations and aggregate counts\n",
    "        total_df = (window_data.groupby(['PULocationID', 'DOLocationID'])\n",
    "                                .agg({'passenger_count': 'sum', 'weight': 'sum'})\n",
    "                                .reset_index()\n",
    "                   )\n",
    "        total_df.rename(columns={'weight': 'edge_weight_taxis', 'passenger_count': 'edge_weight_passengers'}, inplace=True)\n",
    "\n",
    "        G_total = nx.from_pandas_edgelist(total_df, source='PULocationID', target='DOLocationID', edge_attr=['edge_weight_taxis', 'edge_weight_passengers'], create_using=nx.DiGraph)\n",
    "        G_total.remove_edges_from(nx.selfloop_edges(G_total))\n",
    "\n",
    "        window_graphs.append(G_total)\n",
    "        days.append((start_time.strftime('%b-%Y'),end_time.strftime('%b-%Y')))\n",
    "\n",
    "        # Move to the next window with overlap\n",
    "        start_time += overlap_size\n",
    "        end_time += overlap_size\n",
    "        \n",
    "    return window_graphs, days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89618e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_EDA(graphs, window):\n",
    "    \n",
    "    base_eda_dir = f\"{base_dir}\"\n",
    "# =================================================================================================================\n",
    "    # number of edges\n",
    "    num_arcs = [current_graph.number_of_edges() for current_graph in graphs]\n",
    "\n",
    "    df1 = pd.DataFrame({f'n_arcs':num_arcs}, index=window)\n",
    "    df1.plot(figsize=(12, 6), style={f'n_arcs': '-'})\n",
    "    \n",
    "    plt.xlabel('window')\n",
    "    plt.ylabel('count')\n",
    "    plt.xticks(fontsize=7)\n",
    "    \n",
    "    title1 = \"Evolution of no. of edges in Yellow Taxi trips network\"\n",
    "    plt.title(title1)\n",
    "    plt.grid()\n",
    "    plt.legend(['Total edges'])\n",
    "    \n",
    "    temp1 = title1+\".png\"\n",
    "    full_path1 = os.path.join(base_eda_dir,temp1)\n",
    "    if not os.path.exists(base_eda_dir):\n",
    "        os.makedirs(base_eda_dir)\n",
    "    plt.savefig(full_path1, bbox_inches='tight')\n",
    "    plt.show()\n",
    "# ======================================================================================================================\n",
    "    # number of trips\n",
    "\n",
    "    total_weight_taxis = [sum(G.edges[edge]['edge_weight_taxis'] for edge in G.edges()) for G in graphs]\n",
    "    total_weight_passengers = [sum(G.edges[edge]['edge_weight_passengers'] for edge in G.edges()) for G in graphs]\n",
    "\n",
    "    df_new = pd.DataFrame({'n_trips_taxis': total_weight_taxis, 'n_passengers': total_weight_passengers}, index=window)\n",
    "    df_new.plot(figsize=(12, 6), style={'n_trips_taxis': '--', 'n_passengers': '-.'})\n",
    "    \n",
    "    plt.xlabel('window')\n",
    "    plt.ylabel('count')\n",
    "    plt.xticks(fontsize=7)\n",
    "    \n",
    "    title_new = \"Evolution of no. of Yellow Taxi trips\"\n",
    "    plt.title(title_new)\n",
    "    plt.grid()\n",
    "    plt.legend(['Total trips by yellow taxis', 'Total passengers travelled by yellow taxis'])\n",
    "\n",
    "    temp_new = title_new + \".png\"\n",
    "    full_path_new = os.path.join(base_eda_dir, temp_new)\n",
    "    if not os.path.exists(base_eda_dir):\n",
    "        os.makedirs(base_eda_dir)\n",
    "    plt.savefig(full_path_new, bbox_inches='tight')\n",
    "    plt.show()\n",
    "# ======================================================================================================================\n",
    "#     passengers to taxi ratio\n",
    "    \n",
    "    total_weight_taxis = [sum(G.edges[edge]['edge_weight_taxis'] for edge in G.edges()) for G in graphs]\n",
    "    total_weight_passengers = [sum(G.edges[edge]['edge_weight_passengers'] for edge in G.edges()) for G in graphs]\n",
    "\n",
    "    # Calculate the ratio of total_weight_passengers to total_weight_taxis\n",
    "    passenger_to_taxi_ratio = [passengers / taxis if taxis != 0 else 0 for passengers, taxis in zip(total_weight_passengers, total_weight_taxis)]\n",
    "\n",
    "    df_ratio = pd.DataFrame({'passenger_to_taxi_ratio': passenger_to_taxi_ratio}, index=window)\n",
    "    df_ratio.plot(figsize=(12, 6), style={'passenger_to_taxi_ratio': '-'})\n",
    "    \n",
    "    plt.xlabel('window')\n",
    "    plt.ylabel('ratio')\n",
    "    plt.xticks(fontsize=7)\n",
    "    \n",
    "    title_ratio = \"Ratio of total trips by passengers to taxis\"\n",
    "    plt.title(title_ratio)\n",
    "    plt.grid()\n",
    "    plt.legend(['Passenger to Taxi Ratio'])\n",
    "    \n",
    "    temp_ratio = title_ratio + \".png\"\n",
    "    full_path_ratio = os.path.join(base_eda_dir, temp_ratio)\n",
    "    if not os.path.exists(base_eda_dir):\n",
    "        os.makedirs(base_eda_dir)\n",
    "    plt.savefig(full_path_ratio, bbox_inches='tight')\n",
    "    plt.show()\n",
    "# =================================================================================================================\n",
    "#     number of nodes\n",
    "    num_nodes = [current_graph.number_of_nodes() for current_graph in graphs]\n",
    "    \n",
    "    df_nodes = pd.DataFrame({'n_nodes': num_nodes}, index=window)\n",
    "    df_nodes.plot(figsize=(12, 6), style={'n_nodes': '-'})\n",
    "    plt.xlabel('window')\n",
    "    plt.ylabel('count')\n",
    "    plt.xticks(fontsize=7)\n",
    "\n",
    "    title_nodes = \"Evolution of number of zones used by yellow taxis\"\n",
    "    plt.title(title_nodes)\n",
    "    plt.grid()\n",
    "    plt.legend(['Number of zones'])\n",
    "\n",
    "    temp_nodes = title_nodes + \".png\"\n",
    "    full_path_nodes = os.path.join(base_eda_dir, temp_nodes)\n",
    "    if not os.path.exists(base_eda_dir):\n",
    "        os.makedirs(base_eda_dir)\n",
    "    plt.savefig(full_path_nodes, bbox_inches='tight')\n",
    "    plt.show()\n",
    "# ===========================================================================================================================\n",
    "    # Average degree\n",
    "\n",
    "    avg_degree = [sum(dict(G.in_degree()).values()) / len(G) if len(G) > 0 else 0 for G in graphs]\n",
    "\n",
    "    df_avg_degree = pd.DataFrame({'avg_degree': avg_degree}, index=window)\n",
    "    df_avg_degree.plot(figsize=(12, 6), style={'avg_degree': '-'})\n",
    "    plt.xlabel('window')\n",
    "    plt.ylabel('Average Degree')\n",
    "    plt.xticks(fontsize=7)\n",
    "\n",
    "    title_avg_degree = \"Evolution of Average Degree of Yellow Taxi trips\"\n",
    "    plt.title(title_avg_degree)\n",
    "    plt.grid()\n",
    "    plt.legend(['Average degree'])\n",
    "\n",
    "    temp_avg_degree = title_avg_degree + \".png\"\n",
    "    full_path_avg_degree = os.path.join(base_eda_dir, temp_avg_degree)\n",
    "    if not os.path.exists(base_eda_dir):\n",
    "        os.makedirs(base_eda_dir)\n",
    "    plt.savefig(full_path_avg_degree, bbox_inches='tight')\n",
    "    plt.show()\n",
    "# =======================================================================================================================\n",
    "    # Clustering Coefficient\n",
    "    \n",
    "    clustering_coeff = [nx.average_clustering(G) if len(G) > 0 else 0 for G in graphs]\n",
    "\n",
    "    df_clustering_coeff = pd.DataFrame({'clustering_coeff': clustering_coeff}, index=window)\n",
    "    df_clustering_coeff.plot(figsize=(12, 6), style={'clustering_coeff': '-'})\n",
    "    plt.xlabel('window')\n",
    "    plt.ylabel('Clustering Coefficient')\n",
    "    plt.xticks(fontsize=7)\n",
    "\n",
    "    title_clustering_coeff = \"Evolution of clustering coefficient of Yellow Taxi trips\"\n",
    "    plt.title(title_clustering_coeff)\n",
    "    plt.grid()\n",
    "    plt.legend(['Average Clustering Coefficient'])\n",
    "\n",
    "    temp_clustering_coeff = title_clustering_coeff + \".png\"\n",
    "    full_path_clustering_coeff = os.path.join(base_eda_dir, temp_clustering_coeff)\n",
    "    if not os.path.exists(base_eda_dir):\n",
    "        os.makedirs(base_eda_dir)\n",
    "    plt.savefig(full_path_clustering_coeff, bbox_inches='tight')\n",
    "    plt.show()\n",
    "# ===========================================================================================================================  \n",
    "    # Community detection and its similarity\n",
    "    \n",
    "    temp_module = nx.algorithms.community.louvain\n",
    "\n",
    "    list_of_partition_labels = [[0] * 264 for _ in range(len(graphs))]\n",
    "\n",
    "    count = 0\n",
    "    for G in graphs:\n",
    "        if len(G) > 0:\n",
    "            partitions = temp_module.louvain_communities(G, weight='edge_weight_taxis', seed=42)\n",
    "        else:\n",
    "            count += 1\n",
    "            continue\n",
    "\n",
    "        for i in range(len(partitions)):\n",
    "            for item in partitions[i]:\n",
    "                list_of_partition_labels[count][item] = i + 1\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    from sklearn.metrics import adjusted_mutual_info_score as AMI, normalized_mutual_info_score as NMI\n",
    "\n",
    "    sequential_ami_scores = []\n",
    "    first_ami_scores = []\n",
    "    sequential_nmi_scores = []\n",
    "    first_nmi_scores = []\n",
    "\n",
    "    for i in range(len(list_of_partition_labels)):\n",
    "        if i == 0:\n",
    "            ami_score = AMI(list_of_partition_labels[i], list_of_partition_labels[i])\n",
    "            sequential_ami_scores.append(ami_score)\n",
    "            first_ami_scores.append(ami_score)\n",
    "\n",
    "            nmi_score = NMI(list_of_partition_labels[i], list_of_partition_labels[i])\n",
    "            sequential_nmi_scores.append(nmi_score)\n",
    "            first_nmi_scores.append(nmi_score)\n",
    "            continue\n",
    "\n",
    "        non_zero_values_list1 = [x for x, y in zip(list_of_partition_labels[i], list_of_partition_labels[i - 1]) if\n",
    "                                 x != 0 and y != 0]\n",
    "        non_zero_values_list2 = [y for x, y in zip(list_of_partition_labels[i], list_of_partition_labels[i - 1]) if\n",
    "                                 x != 0 and y != 0]\n",
    "\n",
    "        ami_score_sequential = AMI(non_zero_values_list1, non_zero_values_list2)\n",
    "        sequential_ami_scores.append(ami_score_sequential)\n",
    "\n",
    "        nmi_score_sequential = NMI(non_zero_values_list1, non_zero_values_list2)\n",
    "        sequential_nmi_scores.append(nmi_score_sequential)\n",
    "\n",
    "        non_zero_values_list3 = [x for x, y in zip(list_of_partition_labels[i], list_of_partition_labels[0]) if\n",
    "                                 x != 0 and y != 0]\n",
    "        non_zero_values_list4 = [y for x, y in zip(list_of_partition_labels[i], list_of_partition_labels[0]) if\n",
    "                                 x != 0 and y != 0]\n",
    "\n",
    "        first_ami_score = AMI(non_zero_values_list3, non_zero_values_list4)\n",
    "        first_ami_scores.append(first_ami_score)\n",
    "\n",
    "        first_nmi_score = NMI(non_zero_values_list3, non_zero_values_list4)\n",
    "        first_nmi_scores.append(first_nmi_score)\n",
    "\n",
    "    df_community = pd.DataFrame({\n",
    "        f'sequential_ami_scores_{string}': sequential_ami_scores,\n",
    "        f'sequential_nmi_scores_{string}': sequential_nmi_scores,\n",
    "        f'first_ami_scores_{string}': first_ami_scores,\n",
    "        f'first_nmi_scores_{string}': first_nmi_scores\n",
    "    }, index=window)\n",
    "\n",
    "    df_community.plot(figsize=(12, 6), style={\n",
    "        f'sequential_ami_scores_{string}': '-',\n",
    "        f'sequential_nmi_scores_{string}': '--',\n",
    "        f'first_ami_scores_{string}': ':',\n",
    "        f'first_nmi_scores_{string}': '-.'\n",
    "    })\n",
    "\n",
    "    plt.xlabel('window')\n",
    "    plt.ylabel('Similarity value')\n",
    "    plt.xticks(fontsize=7)\n",
    "\n",
    "    title_community = \"Similarity index of communities of Yellow Taxi trips\"\n",
    "    plt.title(title_community)\n",
    "    plt.grid()\n",
    "    plt.legend(['Sequential AMI score', 'Sequential NMI score', 'Partial AMI score', 'Partial NMI score'])\n",
    "\n",
    "    temp_community = title_community + \".png\"\n",
    "    full_path_community = os.path.join(base_eda_dir, temp_community)\n",
    "    if not os.path.exists(base_eda_dir):\n",
    "        os.makedirs(base_eda_dir)\n",
    "    plt.savefig(full_path_community, bbox_inches='tight')\n",
    "    plt.show()\n",
    "# =============================================================================================================================\n",
    "    # Degree Sequence\n",
    "    \n",
    "    high_in_degree_percent = []\n",
    "    high_out_degree_percent = []\n",
    "    low_in_degree_percent = []\n",
    "    low_out_degree_percent = []\n",
    "\n",
    "    for G in graphs:\n",
    "        in_degree_sequence = sorted([d for n, d in G.in_degree()])\n",
    "\n",
    "        high_in_nums = [d for d in in_degree_sequence if d >= 0.6 * (G.number_of_nodes())]\n",
    "        low_in_nums = [d for d in in_degree_sequence if d <= 0.1 * (G.number_of_nodes())]\n",
    "\n",
    "        out_degree_sequence = sorted([d for n, d in G.out_degree()])\n",
    "\n",
    "        high_out_nums = [d for d in out_degree_sequence if d >= 0.6 * (G.number_of_nodes())]\n",
    "        low_out_nums = [d for d in out_degree_sequence if d <= 0.1 * (G.number_of_nodes())]\n",
    "\n",
    "        high_in_degree_percent.append(len(high_in_nums) * 100 / (G.number_of_nodes()) if len(G) > 0 else 0)\n",
    "        high_out_degree_percent.append(len(high_out_nums) * 100 / (G.number_of_nodes()) if len(G) > 0 else 0)\n",
    "        low_in_degree_percent.append(len(low_in_nums) * 100 / (G.number_of_nodes()) if len(G) > 0 else 0)\n",
    "        low_out_degree_percent.append(len(low_out_nums) * 100 / (G.number_of_nodes()) if len(G) > 0 else 0)\n",
    "\n",
    "    df_degree_percent = pd.DataFrame({\n",
    "        f'high_in_degree_percent_{string}': high_in_degree_percent,\n",
    "        f'high_out_degree_percent_{string}': high_out_degree_percent,\n",
    "        f'low_in_degree_percent_{string}': low_in_degree_percent,\n",
    "        f'low_out_degree_percent_{string}': low_out_degree_percent\n",
    "    }, index=window)\n",
    "\n",
    "    df_degree_percent.plot(figsize=(12, 6), style={\n",
    "        f'high_in_degree_percent_{string}': '-',\n",
    "        f'high_out_degree_percent_{string}': '--',\n",
    "        f'low_in_degree_percent_{string}': ':',\n",
    "        f'low_out_degree_percent_{string}': '-.'\n",
    "    })\n",
    "\n",
    "    plt.xlabel('window')\n",
    "    plt.ylabel('Percentage(%)')\n",
    "    plt.xticks(fontsize=7)\n",
    "\n",
    "    title_degree_percent = \"Number of highly busy and least busy Yellow Taxi zones\"\n",
    "    plt.title(title_degree_percent)\n",
    "    plt.grid()\n",
    "    plt.legend([\n",
    "        'High incoming traffic(>= 60% of nodes)',\n",
    "        'High outgoing traffic(>= 60% of nodes)',\n",
    "        'Low incoming traffic(<= 10% of nodes)',\n",
    "        'Low outgoing traffic(<= 10% of nodes)'\n",
    "    ])\n",
    "\n",
    "    temp_degree_percent = title_degree_percent + \".png\"\n",
    "    full_path_degree_percent = os.path.join(base_eda_dir, temp_degree_percent)\n",
    "    if not os.path.exists(base_eda_dir):\n",
    "        os.makedirs(base_eda_dir)\n",
    "    plt.savefig(full_path_degree_percent, bbox_inches='tight')\n",
    "    plt.show()\n",
    "# ==============================================================================================================================\n",
    "    # Centrality measures\n",
    "\n",
    "    in_degree_centrality = [0] * 263\n",
    "    out_degree_centrality = [0] * 263\n",
    "    betweenness_centrality = [0] * 263  # without weights\n",
    "    eigenvector_centrality = [0] * 263  # with weights\n",
    "\n",
    "    for G in graphs:\n",
    "\n",
    "        if len(G) == 0:\n",
    "            continue\n",
    "\n",
    "        in_degrees = nx.in_degree_centrality(G)\n",
    "        out_degrees = nx.out_degree_centrality(G)\n",
    "        betweenness = nx.betweenness_centrality(G)\n",
    "        eigenvector = nx.eigenvector_centrality(G, max_iter=1000, tol=1e-4, weight='edge_weight_taxis')\n",
    "\n",
    "        max_in = max(in_degrees.values())\n",
    "        max_out = max(out_degrees.values())\n",
    "        max_betweenness = max(betweenness.values())\n",
    "        max_eigenvector = max(eigenvector.values())\n",
    "\n",
    "        max_ins = [key for key, value in in_degrees.items() if value == max_in]\n",
    "        max_outs = [key for key, value in out_degrees.items() if value == max_out]\n",
    "        max_betweenness_s = [key for key, value in betweenness.items() if value == max_betweenness]\n",
    "        max_eigenvectors = [key for key, value in eigenvector.items() if value == max_eigenvector]\n",
    "\n",
    "        in_degree_centrality = [val + 1 if idx in max_ins else val for idx, val in enumerate(in_degree_centrality)]\n",
    "        out_degree_centrality = [val + 1 if idx in max_outs else val for idx, val in enumerate(out_degree_centrality)]\n",
    "        betweenness_centrality = [val + 1 if idx in max_betweenness_s else val for idx, val in enumerate(betweenness_centrality)]\n",
    "        eigenvector_centrality = [val + 1 if idx in max_eigenvectors else val for idx, val in enumerate(eigenvector_centrality)]\n",
    "\n",
    "    in_degree_centrality = {index: value for index, value in enumerate(in_degree_centrality)}\n",
    "    out_degree_centrality = {index: value for index, value in enumerate(out_degree_centrality)}\n",
    "    betweenness_centrality = {index: value for index, value in enumerate(betweenness_centrality)}\n",
    "    eigenvector_centrality = {index: value for index, value in enumerate(eigenvector_centrality)}\n",
    "\n",
    "    sorted_in_degree_centrality = dict(sorted(in_degree_centrality.items(), key=lambda item: item[1], reverse=True))\n",
    "    sorted_out_degree_centrality = dict(sorted(out_degree_centrality.items(), key=lambda item: item[1], reverse=True))\n",
    "    sorted_betweenness_centrality = dict(sorted(betweenness_centrality.items(), key=lambda item: item[1], reverse=True))\n",
    "    sorted_eigenvector_centrality = dict(sorted(eigenvector_centrality.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    top_10_in_degree = dict(list(sorted_in_degree_centrality.items())[:10])\n",
    "    top_10_out_degree = dict(list(sorted_out_degree_centrality.items())[:10])\n",
    "    top_10_betweenness = dict(list(sorted_betweenness_centrality.items())[:10])\n",
    "    top_10_eigenvector = dict(list(sorted_eigenvector_centrality.items())[:10])\n",
    "\n",
    "    zones = pd.read_csv('Data/taxi_zone_lookup.csv')\n",
    "    zones = zones.drop(['Borough', 'service_zone'], axis=1)\n",
    "# =======================================================================================================================\n",
    "    # in degree centrality\n",
    "    top_non_zero_in_degree = {k: v for k, v in top_10_in_degree.items() if v != 0}\n",
    "    nodes_strings_in_degree = [zones.loc[zones['LocationID'] == node + 1, 'Zone'].iloc[0] for node in top_non_zero_in_degree.keys()]\n",
    "    frequencies_in_degree = list(top_non_zero_in_degree.values())\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(nodes_strings_in_degree, frequencies_in_degree)  # Flip x and y axis\n",
    "    \n",
    "    plt.ylabel('Zone')  # Set y-axis label\n",
    "    plt.xlabel('Frequency')  # Set x-axis label\n",
    "    \n",
    "    title7 = \"Most central zones based on in degree centrality\"\n",
    "    plt.title(title7)\n",
    "    \n",
    "    temp7 = title7.replace(' ', '_') + \".png\"\n",
    "    full_path7 = os.path.join(base_eda_dir, temp7)\n",
    "    if not os.path.exists(base_eda_dir):\n",
    "        os.makedirs(base_eda_dir)\n",
    "    plt.savefig(full_path7, bbox_inches='tight')\n",
    "    plt.show()\n",
    "# ========================================================================================================================\n",
    "    # out degree centrality\n",
    "    top_non_zero_out_degree = {k: v for k, v in top_10_out_degree.items() if v != 0}\n",
    "    nodes_strings_out_degree = [zones.loc[zones['LocationID'] == node + 1, 'Zone'].iloc[0] for node in top_non_zero_out_degree.keys()]\n",
    "    frequencies_out_degree = list(top_non_zero_out_degree.values())\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(nodes_strings_out_degree, frequencies_out_degree)  # Flip x and y axis\n",
    "    \n",
    "    plt.ylabel('Zone')  # Set y-axis label\n",
    "    plt.xlabel('Frequency')  # Set x-axis label\n",
    "    \n",
    "    title8 = \"Most central zones based on out degree centrality\"\n",
    "    plt.title(title8)\n",
    "    \n",
    "    temp8 = title8.replace(' ', '_') + \".png\"\n",
    "    full_path8 = os.path.join(base_eda_dir, temp8)\n",
    "    if not os.path.exists(base_eda_dir):\n",
    "        os.makedirs(base_eda_dir)\n",
    "    plt.savefig(full_path8, bbox_inches='tight')\n",
    "    plt.show()\n",
    "# ===================================================================================================================\n",
    "    # betweenness centrality\n",
    "    top_non_zero_betweenness = {k: v for k, v in top_10_betweenness.items() if v != 0}\n",
    "    nodes_strings_betweenness = [zones.loc[zones['LocationID'] == node + 1, 'Zone'].iloc[0] for node in top_non_zero_betweenness.keys()]\n",
    "    frequencies_betweenness = list(top_non_zero_betweenness.values())\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(nodes_strings_betweenness, frequencies_betweenness)  # Flip x and y axis\n",
    "    \n",
    "    plt.ylabel('Zone')  # Set y-axis label\n",
    "    plt.xlabel('Frequency')  # Set x-axis label\n",
    "    \n",
    "    title9 = \"Most central zones based on betweenness centrality\"\n",
    "    plt.title(title9)\n",
    "    \n",
    "    temp9 = title9.replace(' ', '_') + \".png\"\n",
    "    full_path9 = os.path.join(base_eda_dir, temp9)\n",
    "    if not os.path.exists(base_eda_dir):\n",
    "        os.makedirs(base_eda_dir)\n",
    "    plt.savefig(full_path9, bbox_inches='tight')\n",
    "    plt.show()\n",
    "# ==========================================================================================================================\n",
    "    # eigenvector centrality\n",
    "    top_non_zero_eigenvector = {k: v for k, v in top_10_eigenvector.items() if v != 0}\n",
    "    nodes_strings_eigenvector = [zones.loc[zones['LocationID'] == node + 1, 'Zone'].iloc[0] for node in top_non_zero_eigenvector.keys()]\n",
    "    frequencies_eigenvector = list(top_non_zero_eigenvector.values())\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(nodes_strings_eigenvector, frequencies_eigenvector)  # Flip x and y axis\n",
    "    \n",
    "    plt.ylabel('Zone')  # Set y-axis label\n",
    "    plt.xlabel('Frequency')  # Set x-axis label\n",
    "    \n",
    "    title10 = \"Most central zones based on eigenvector centrality\"\n",
    "    plt.title(title10)\n",
    "    \n",
    "    temp10 = title10.replace(' ', '_') + \".png\"\n",
    "    full_path10 = os.path.join(base_eda_dir, temp10)\n",
    "    if not os.path.exists(base_eda_dir):\n",
    "        os.makedirs(base_eda_dir)\n",
    "    plt.savefig(full_path10, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c47e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('give your taxi path here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ce1e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_graphs, years = sliding_window_graph_creation(df, 12, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0914c40a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph_EDA(yearly_graphs, years)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
